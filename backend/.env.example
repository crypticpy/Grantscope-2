# =============================================================================
# Environment Configuration
# =============================================================================

# Application environment: "development" or "production"
# Controls CORS behavior and other environment-specific settings
# - development: allows localhost origins (http://localhost:3000, etc.)
# - production: requires HTTPS origins only, rejects localhost
ENVIRONMENT=development

# =============================================================================
# CORS Configuration
# =============================================================================
# Comma-separated list of allowed origins for CORS requests
#
# In PRODUCTION (ENVIRONMENT=production):
#   - All origins MUST use HTTPS
#   - localhost/127.0.0.1 origins are automatically rejected
#   - Default: https://foresight.vercel.app
#   - Empty/invalid origins are filtered out
#
# In DEVELOPMENT (ENVIRONMENT=development or unset):
#   - HTTP localhost origins are allowed
#   - Default: http://localhost:3000,http://localhost:5173,http://localhost:5174
#
# Examples:
#   Production: ALLOWED_ORIGINS=https://foresight.vercel.app,https://api.foresight.app
#   Development: ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:5174

# =============================================================================
# Security Configuration
# =============================================================================

# Number of trusted reverse proxies in front of the application
# Used for accurate client IP extraction (anti-spoofing for rate limiting)
# - Railway: typically 1
# - Behind Cloudflare + Railway: 2
# Default: 1
TRUSTED_PROXY_COUNT=1

# Rate limit: requests per minute per IP address
# Default: 100
RATE_LIMIT_PER_MINUTE=100

# Maximum request body size in megabytes
# Default: 10
MAX_REQUEST_SIZE_MB=10

# =============================================================================
# Background Worker Configuration (RECOMMENDED)
# =============================================================================
# Long-running jobs (deep research, discovery, briefs) are executed by a
# dedicated worker process (`python -m app.worker`) so they survive web restarts.
#
# - Web service: set FORESIGHT_PROCESS_TYPE=web (default)
# - Worker service: set FORESIGHT_PROCESS_TYPE=worker
FORESIGHT_PROCESS_TYPE=web

# Enable APScheduler jobs (nightly scan + weekly discovery).
# IMPORTANT: enable this ONLY on the worker service to avoid duplicate runs.
FORESIGHT_ENABLE_SCHEDULER=false

# Worker polling interval for queued jobs (seconds)
FORESIGHT_WORKER_POLL_INTERVAL_SECONDS=5

# Worker health server:
# - If PORT is set (Railway), defaults to true and serves `/api/v1/health`.
# - For local dev, default is false (prevents port conflicts with the API server).
FORESIGHT_WORKER_HEALTH_SERVER=false

# Per-job watchdog timeouts (seconds)
FORESIGHT_BRIEF_TIMEOUT_SECONDS=1800
FORESIGHT_DISCOVERY_TIMEOUT_SECONDS=5400

# Research task timeouts (seconds)
RESEARCH_TASK_TIMEOUT_UPDATE_SECONDS=900
RESEARCH_TASK_TIMEOUT_DEEP_RESEARCH_SECONDS=2700
RESEARCH_TASK_TIMEOUT_WORKSTREAM_ANALYSIS_SECONDS=2700
RESEARCH_TASK_QUEUED_TIMEOUT_SECONDS=900

# =============================================================================
# Supabase Configuration
# =============================================================================
SUPABASE_URL=your_supabase_project_url
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_key

# =============================================================================
# Azure OpenAI Configuration (REQUIRED)
# =============================================================================
# The application uses Azure OpenAI exclusively - no fallback to OpenAI.
# App will fail to start if these are not configured.

# Azure OpenAI endpoint URL
AZURE_OPENAI_ENDPOINT=https://aph-cognitive-sandbox-openai-eastus2.openai.azure.com

# Azure OpenAI API key
AZURE_OPENAI_KEY=your-azure-openai-key

# API version for chat completions (gpt-4.1, gpt-4.1-mini)
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# API version for embeddings (text-embedding-ada-002)
# Note: Embeddings require a different (older) API version
AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15

# Deployment names (Azure-specific model deployment names)
# These map to the deployed models in your Azure OpenAI resource
AZURE_OPENAI_DEPLOYMENT_CHAT=gpt-4.1
AZURE_OPENAI_DEPLOYMENT_CHAT_MINI=gpt-4.1-mini
AZURE_OPENAI_DEPLOYMENT_EMBEDDING=text-embedding-ada-002

# =============================================================================
# Legacy OpenAI Configuration (DEPRECATED - no longer used)
# =============================================================================
# OPENAI_API_KEY=your_openai_api_key  # Not used - Azure OpenAI only

# =============================================================================
# GPT Researcher Configuration (AUTO-CONFIGURED)
# =============================================================================
# GPT Researcher is automatically configured using the Azure OpenAI settings above.
# The app translates our config to GPT Researcher's expected format at runtime:
#
# Our Config                          -> GPT Researcher Format
# AZURE_OPENAI_DEPLOYMENT_CHAT        -> SMART_LLM=azure_openai:gpt-4.1
# AZURE_OPENAI_DEPLOYMENT_CHAT_MINI   -> FAST_LLM=azure_openai:gpt-4.1-mini
# AZURE_OPENAI_DEPLOYMENT_EMBEDDING   -> EMBEDDING=azure_openai:text-embedding-ada-002
# AZURE_OPENAI_KEY                    -> AZURE_OPENAI_API_KEY
# AZURE_OPENAI_API_VERSION            -> OPENAI_API_VERSION
#
# You do NOT need to set SMART_LLM, FAST_LLM, or EMBEDDING manually.
# The research_service.py handles this translation automatically.
#
# Scraper note:
# - If FIRECRAWL_API_KEY is set, the app will default GPT Researcher to SCRAPER=firecrawl
# - Otherwise it defaults to SCRAPER=bs (BeautifulSoup)

# =============================================================================
# External API Keys
# =============================================================================

# Tavily API (Required for GPT Researcher web search)
# Get your API key at https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key

# Firecrawl API (Optional, improves source content extraction)
# Get your API key at https://firecrawl.dev/
FIRECRAWL_API_KEY=your_firecrawl_api_key

# Optional: custom Firecrawl server URL (defaults to https://api.firecrawl.dev)
FIRECRAWL_SERVER_URL=https://api.firecrawl.dev

# Optional: NewsAPI for content fetching
NEWSAPI_KEY=your_newsapi_key

# Optional: Additional API keys for content sources
GOOGLE_NEWS_API_KEY=your_google_news_api_key
