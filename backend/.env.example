# =============================================================================
# Environment Configuration
# =============================================================================

# Application environment: "development" or "production"
# Controls CORS behavior and other environment-specific settings
# - development: allows localhost origins (http://localhost:3000, etc.)
# - production: requires HTTPS origins only, rejects localhost
ENVIRONMENT=development

# =============================================================================
# CORS Configuration
# =============================================================================
# Comma-separated list of allowed origins for CORS requests
#
# In PRODUCTION (ENVIRONMENT=production):
#   - All origins MUST use HTTPS
#   - localhost/127.0.0.1 origins are automatically rejected
#   - Default: https://grantscope.vercel.app
#   - Empty/invalid origins are filtered out
#
# In DEVELOPMENT (ENVIRONMENT=development or unset):
#   - HTTP localhost origins are allowed
#   - Default: http://localhost:3000,http://localhost:5173,http://localhost:5174
#
# Examples:
#   Production: ALLOWED_ORIGINS=https://grantscope.vercel.app,https://api.grantscope.app
#   Development: ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:5174

# =============================================================================
# Security Configuration
# =============================================================================

# Number of trusted reverse proxies in front of the application
# Used for accurate client IP extraction (anti-spoofing for rate limiting)
# - Azure Container Apps: typically 1
# - Behind Cloudflare + Azure: 2
# Default: 1
TRUSTED_PROXY_COUNT=1

# Rate limit: requests per minute per IP address
# Default: 100
RATE_LIMIT_PER_MINUTE=100

# Maximum request body size in megabytes
# Default: 10
MAX_REQUEST_SIZE_MB=10

# =============================================================================
# Background Worker Configuration (RECOMMENDED)
# =============================================================================
# Long-running jobs (deep research, discovery, briefs) are executed by a
# dedicated worker process (`python -m app.worker`) so they survive web restarts.
#
# - Web service: set GRANTSCOPE_PROCESS_TYPE=web (default)
# - Worker service: set GRANTSCOPE_PROCESS_TYPE=worker
GRANTSCOPE_PROCESS_TYPE=web

# Enable APScheduler jobs (nightly scan + weekly discovery).
# IMPORTANT: enable this ONLY on the worker service to avoid duplicate runs.
GRANTSCOPE_ENABLE_SCHEDULER=false

# Worker polling interval for queued jobs (seconds)
GRANTSCOPE_WORKER_POLL_INTERVAL_SECONDS=5

# Worker health server:
# - If PORT is set (Azure Container Apps), defaults to true and serves `/api/v1/health`.
# - For local dev, default is false (prevents port conflicts with the API server).
GRANTSCOPE_WORKER_HEALTH_SERVER=false

# Per-job watchdog timeouts (seconds)
GRANTSCOPE_BRIEF_TIMEOUT_SECONDS=1800
GRANTSCOPE_DISCOVERY_TIMEOUT_SECONDS=5400

# Research task timeouts (seconds)
RESEARCH_TASK_TIMEOUT_UPDATE_SECONDS=900
RESEARCH_TASK_TIMEOUT_DEEP_RESEARCH_SECONDS=2700
RESEARCH_TASK_TIMEOUT_WORKSTREAM_ANALYSIS_SECONDS=2700
RESEARCH_TASK_QUEUED_TIMEOUT_SECONDS=900

# =============================================================================
# Database / Supabase Configuration
# =============================================================================
# GrantScope supports two modes:
#
# MODE 1 — Self-hosted (docker compose):
#   Uses local PostgreSQL + PostgREST + GoTrue via the nginx gateway.
#   The gateway mirrors Supabase's URL structure (/rest/v1, /auth/v1)
#   so supabase-py works without code changes.
#
#   SUPABASE_URL=http://gateway:8000          (set automatically by docker-compose)
#   SUPABASE_URL=http://localhost:3000        (for running backend outside docker)
#
#   Generate keys with: python infra/generate_keys.py
#
# MODE 2 — Supabase Cloud:
#   SUPABASE_URL=https://your-project.supabase.co
#
# Both modes use the same SUPABASE_ANON_KEY and SUPABASE_SERVICE_KEY format.
# For self-hosted, generate them with infra/generate_keys.py.
# For Supabase Cloud, copy them from your project dashboard.

SUPABASE_URL=http://localhost:3000
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_key

# JWT secret — MUST match across PostgREST, GoTrue, and generate_keys.py
# Only needed for self-hosted mode. Generate with: python infra/generate_keys.py
# JWT_SECRET=your-jwt-secret-at-least-32-characters

# =============================================================================
# Azure PostgreSQL (SQLAlchemy) — Primary database for new features
# =============================================================================
# Format: postgresql+asyncpg://user:password@host:port/dbname
# Used by SQLAlchemy for migrated routers (wizard, proposals, applications).
# Non-migrated services still use the Supabase config above during transition.
DATABASE_URL=postgresql+asyncpg://gsadmin:your-password@grantscope-db.postgres.database.azure.com:5432/grantscope

# Set to "true" to log all SQL queries (noisy — dev only)
# SQLALCHEMY_ECHO=false

# =============================================================================
# Azure Blob Storage — Application attachments
# =============================================================================
# Connection string from Azure Portal > Storage Account > Access Keys
AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=grantscoperesources;AccountKey=your-key;EndpointSuffix=core.windows.net

# =============================================================================
# Azure OpenAI Configuration (REQUIRED)
# =============================================================================
# The application uses Azure OpenAI exclusively - no fallback to OpenAI.
# App will fail to start if these are not configured.

# Azure OpenAI endpoint URL
AZURE_OPENAI_ENDPOINT=https://aph-cognitive-sandbox-openai-eastus2.openai.azure.com

# Azure OpenAI API key
AZURE_OPENAI_KEY=your-azure-openai-key

# API version for chat completions (gpt-4.1, gpt-4.1-mini)
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# API version for embeddings (text-embedding-ada-002)
# Note: Embeddings require a different (older) API version
AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15

# Deployment names (Azure-specific model deployment names)
# These map to the deployed models in your Azure OpenAI resource
AZURE_OPENAI_DEPLOYMENT_CHAT=gpt-4.1
AZURE_OPENAI_DEPLOYMENT_CHAT_MINI=gpt-4.1-mini
AZURE_OPENAI_DEPLOYMENT_EMBEDDING=text-embedding-ada-002

# =============================================================================
# Legacy OpenAI Configuration (DEPRECATED - no longer used)
# =============================================================================
# OPENAI_API_KEY=your_openai_api_key  # Not used - Azure OpenAI only

# =============================================================================
# GPT Researcher Configuration (AUTO-CONFIGURED)
# =============================================================================
# GPT Researcher is automatically configured using the Azure OpenAI settings above.
# The app translates our config to GPT Researcher's expected format at runtime:
#
# Our Config                          -> GPT Researcher Format
# AZURE_OPENAI_DEPLOYMENT_CHAT        -> SMART_LLM=azure_openai:gpt-4.1
# AZURE_OPENAI_DEPLOYMENT_CHAT_MINI   -> FAST_LLM=azure_openai:gpt-4.1-mini
# AZURE_OPENAI_DEPLOYMENT_EMBEDDING   -> EMBEDDING=azure_openai:text-embedding-ada-002
# AZURE_OPENAI_KEY                    -> AZURE_OPENAI_API_KEY
# AZURE_OPENAI_API_VERSION            -> OPENAI_API_VERSION
#
# You do NOT need to set SMART_LLM, FAST_LLM, or EMBEDDING manually.
# The research_service.py handles this translation automatically.
#
# Scraper: GPT Researcher uses SCRAPER=bs (BeautifulSoup) for local content extraction.
# Retriever: GPT Researcher uses SearXNG for search via RETRIEVER=searx.
# Both are auto-configured — no manual setup needed.

# =============================================================================
# Search Provider Configuration
# =============================================================================
# Controls which search backend is used for discovery and research.
#
# SEARCH_PROVIDER options:
#   auto    — (default) tries SearXNG first, then Serper, then Tavily
#   searxng — self-hosted SearXNG meta-search engine (zero API cost)
#   serper  — Serper.dev Google Search API (paid)
#   tavily  — Tavily search API (paid)
#
# For self-hosted deployments, use SearXNG with docker-compose.yml
# For cloud deployments without SearXNG, set to serper or tavily
SEARCH_PROVIDER=auto

# SearXNG self-hosted search (zero API cost, runs alongside the app)
# Set this to your SearXNG instance URL. In docker-compose: http://searxng:8080
# If not set, SearXNG is skipped and the system falls back to paid APIs.
# SEARXNG_BASE_URL=http://localhost:8888

# SEARX_URL is used by GPT Researcher's built-in searx retriever.
# Auto-configured from SEARXNG_BASE_URL — only set if they differ.
# SEARX_URL=http://localhost:8888

# =============================================================================
# External API Keys
# =============================================================================

# Serper.dev API (paid search backend, used when SEARCH_PROVIDER=serper or auto)
# Google Search + News via API — $1/1K queries, 2500 free
# Get your API key at https://serper.dev/
SERPER_API_KEY=your_serper_api_key

# Tavily API (Optional paid fallback for search)
# Get your API key at https://tavily.com/
TAVILY_API_KEY=your_tavily_api_key

# SAM.gov API (free key from api.data.gov)
SAM_GOV_API_KEY=

# =============================================================================
# Gamma.app API (Optional - AI-powered presentation generation)
# =============================================================================
# Gamma.app creates polished, AI-generated presentations from brief content.
# If not configured, falls back to local python-pptx generation.
# Get API access at https://gamma.app/pricing (Pro plan or higher required)

# Gamma API key (starts with sk-gamma-)
GAMMA_API_KEY=sk-gamma-your-api-key

# Enable/disable Gamma integration (defaults to true if API key is set)
GAMMA_API_ENABLED=true

# City of Austin logo URL for presentation branding
# Used in slide headers for professional branding
COA_LOGO_URL=https://austin.widen.net/content/sk8xr1ne/png/COA-Logo-Horizontal-Official-RGB.png
